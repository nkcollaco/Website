---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "SDS348"
date: "5/1/2020"
output:
  pdf_document: default
  html_document:
  df_print: paged
---
# Noah Collaco nkc383
```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

```{R}
class_diag <- function(probs,truth){
  
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
```

```{R}
library(readxl)
RankedMeasuredData <- read_excel("2020 County Health Rankings Data - v1.xlsx", 
    sheet = "Ranked Measure Data")
AdditionalMeasureData <- read_excel("2020 County Health Rankings Data - v1.xlsx", 
    sheet = "Additional Measure Data")
Education <- read_excel("Education.xls")
Education%>% filter(State=="TX")->TXEducation
RankedMeasuredData%>% filter(State=="Texas")-> RankedMeasuredData
AdditionalMeasureData%>% filter(State=="Texas")-> AdditionalMeasureData
TXEducation%>% rename(c("County"=`Area name`))->TXEducation
left_join(RankedMeasuredData,TXEducation, by="County")->partialdata
left_join(partialdata, AdditionalMeasureData, by="County")->fulldata
head(fulldata)
fulldata%>%select(County,`Life Expectancy`,`% Adults with Obesity`,`% Physically Inactive`,`% Smokers`,`% Food Insecure`,`% Uninsured`,`% Adults with Diabetes`,`Percent of adults with a bachelor's degree or higher, 2014-18` , `Median Household Income`, `% Insufficient Sleep`,`% Excessive Drinking`,`% Rural`)->project2
project2%>% na.omit()->project2
project2%>% rename(Lifeexpt=`Life Expectancy`)%>% rename(pctObese=`% Adults with Obesity`)%>% rename(pctInactive=`% Physically Inactive`)%>% rename(pctFDInsecure=`% Food Insecure`)%>% rename(pctSmokers=`% Smokers`)%>% rename(pctUninsured=`% Uninsured`)%>% rename(pctDiabetes=`% Adults with Diabetes`)%>% rename(pctBachelors=`Percent of adults with a bachelor's degree or higher, 2014-18`)%>% rename(medianincome=`Median Household Income`)%>% rename(pctinsufficientsleep=`% Insufficient Sleep`)%>% rename(pctRural=`% Rural`)%>% rename(pctexcessdrinking=`% Excessive Drinking`)->project2
project2%>% mutate(`Rural/Urban`=if_else(pctRural>50, "Mostly Rural", "Mostly Urban"))->project2
glimpse(project2)

```

This project uses data from the 2019 County Health Rankings for Texas and the USDA ERS Educational Attainment Data.. Each of the data sources were filtered for Texas counties. I wanted to compared how different variables affected Life Expectancy within a county. The variables that were chosen were Obesity Rate, Inactivty Rate, Smoking Rate, Food Insecurity Rate, percent Uninsured, Diabetes Rate, Percent of a county with a bachelors degree, Food Environemnt Index, Percen Insufficient Sleep, percent Excessive drinking, and Percent Rural. The dataset was then filtered to get rid of NAs as there were some counties without measurements for Life Expectancy. This brought down the number of observations from 254 counties to 237 counties.The percent Rural variable was also mutated to be a categorical variable of Mostly Rural and Mostly Urban. 

# Manova
```{R}
man1<-manova(cbind(Lifeexpt, pctObese, pctInactive, pctSmokers, pctFDInsecure, pctDiabetes,pctBachelors,medianincome,pctinsufficientsleep,pctexcessdrinking )~`Rural/Urban`, data=project2)
summary(man1)
summary.aov(man1)
project2%>% group_by(`Rural/Urban`)%>% summarize( mean(Lifeexpt), mean(pctObese),mean(pctInactive),mean(pctSmokers), mean(pctFDInsecure), mean(pctDiabetes),mean(pctBachelors),mean(medianincome),mean(pctinsufficientsleep),mean(pctexcessdrinking))
pairwise.t.test(project2$Lifeexpt,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctInactive,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctFDInsecure,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctDiabetes,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctBachelors,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$medianincome,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctinsufficientsleep,project2$`Rural/Urban`,p.adj="none")
pairwise.t.test(project2$pctexcessdrinking,project2$`Rural/Urban`,p.adj="none")
1-.95^28
.05/28
```
The MANOVA test was performed for all of the variables except pctRural to determine whether there was a mean difference across the Rural/Urban categorical variable. The overall Manova was significant with a Pillai trace of 0.33048 and a p-value of  8.078e-15. Univariate ANOVAS were then performed which showed that life expectancy, percent inactivity, percent food insecure, percent diabetes, percent diabetes, percent bachelors, median income, percent insufficient sleep, and percent excess drinking differed signifiantly between mostly urban and mostly rural counties. Paired t-test were then percformed with the variables that were significant under the univeriate ANOVAS. The probability of at least one type I error if unadjusted would be 76,22%. The signifiance is adjusted to .001785 as the number of tests performed in total is 28. This means that only percent insufficient sleep and percent food insecure remain significantly different between counties. MANOVA assumptions of random samples, liniear relationships, homogeneity and multivariate normality, and no multicollinearity are likely violated. With this type of data these asssumptions are not likely to have been met. 

# Randomization Test 
```{R}
project2%>% group_by(`Rural/Urban`)%>% summarize(mean=mean(Lifeexpt))%>% summarize(diff(mean))
  


rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(Lifeexp=sample(project2$Lifeexpt), urbanorurual=project2$`Rural/Urban`) 
rand_dist[i]<-mean(new[new$urbanorurual=="Mostly Urban",]$Lifeexp)-
  mean(new[new$urbanorurual=="Mostly Rural",]$Lifeexp)
}



mean(rand_dist< -.8304265		 | rand_dist>0.8304265		)
hist(rand_dist, main = "", ylab = ""); abline(v=-0.8304265	, col="red");abline(v=0.8247375	, col="red")


```
A randomization test was performed on one of the variables that was significant in the univariate ANOVAS, Life expectancy. The randomization test was performed for the mean differences between the Mostly Urban and Mostly Rural counties. The null hypothesis is that the differences in the means are equal to zero. The alternative hypothesis is that the differences in the means between the two group are not equal to zero. The differences in the mean between the rural and urban counties in the dataset is .84042. The two-tailed p-value is computed by seeing the proportion of the mean differnces under the simulated null hypothesis that are more extreme than the actual value of plus or minus .8304265. Ultimately the computed p-value was .0076, which is well below the necessary p-value of .05. This means that the null hypothesis can be rejected and we can conclude that there is indeed a significant difference in the means between the two groups. 

# Linear Regression 
```{R}
project2$pctObese_c<-(project2$pctObese-mean(project2$pctObese))
project2$pctSmokers_c<-(project2$pctSmokers-mean(project2$pctSmokers))
project2$pctexcessdrinking_c<-(project2$pctexcessdrinking-mean(project2$pctexcessdrinking))
project2$pctFDInsecure_c<-(project2$pctFDInsecure-mean(project2$pctFDInsecure))
fit1<-lm(Lifeexpt~pctObese_c*pctSmokers_c*pctFDInsecure_c*pctexcessdrinking_c ,data=project2)
summary(fit1)
ggplot(project2, aes(x=Lifeexpt, y=pctSmokers_c))+geom_point()+
  geom_smooth(method="lm",formula=y~x,se=F,fullrange=T,aes())+ggtitle("Life Expectancy and the Percentage of Smokers in a TX County")+xlab("Life Expectancy")+ylab("Percent Smokers Mean Centered ")
ggplot(project2, aes(x=Lifeexpt, y=pctFDInsecure_c))+geom_point()+
  geom_smooth(method="lm",formula=y~x,se=F,fullrange=T,aes())+ggtitle("Life Expectancy and the Percentage Food Insecurity in a TX County")+xlab("Life Expectancy")+ylab("Percent Food Insecure Mean Centered ")
resids<-fit1$residuals
fitvals<-fit1$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, col="red")
ggplot()+geom_histogram(aes(resids), bins=20)
ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids))
ks.test(resids, "pnorm", mean=0, sd(resids))
library(sandwich)
library(lmtest)
bptest(fit1)
coeftest(fit1)
coeftest(fit1, vcov = vcovHC(fit1)) 
```
This model was created by using the variables of percent obesity, percent smokers, percent Food Insecure, and percent excessive drinking as well as their interactions to predict life expectancy. The numeric predictors were first mean centered. The main coefficients for this model are all negative (-.069, -.53, -.12, -.069) which means that with each 1% increase in these variables will result in a -.069, -.53, -.11, -.059 reduction in life expectancy for the county respectively. The interactions of the variables range from both negative to postive effects the two effects that are significant are pctSmokers_c:pctexcessdrinking_c with a slope of-.19 and pctFDInsecure_c:pctexcessdrinking_c with a slope of .10.
Based on the graphs overall the assumptions of linearity, normality, and homoskedasticity seem to be met, but there are definitely outliers that can be seen in each of the plots. The KS test also shows a p-value of .057, although it is low it means that the null hypothesis cannot be rejected. 
Based on the regression with robust standard errors there was not many major changes other than the standard errors decreasing for some variables. The significance of all of the variables was also reduced under the robust standard erors regression. 
The Multiple R-squared was 0.3559 which means that this linear regression model explains .3559 of the variance in life expectancy among texas counties. 

# Linear Regression with boostrapped Standard errors
```{R}
samp_distn<-replicate(5000, {
  boot_dat<- sample_frac(project2, replace=T )
fit <- lm(Lifeexpt~pctObese_c*pctSmokers_c*pctFDInsecure_c*pctexcessdrinking_c ,data=boot_dat) 
coef(fit)
})
samp_distn%>% t%>% as.data.frame%>% summarize_all(sd)
```
The SE in the bootstrapped model has standard errors that are smaller than both the original and robust standard errors that were calculated previously. 

# Logistic Regression 
```{R}
library(lmtest)
project2%>% mutate(y=ifelse(`Rural/Urban`=="Mostly Urban",1,0))->project2
fit2<-glm(y~Lifeexpt+pctinsufficientsleep, data=project2, family = "binomial")
coeftest(fit2)
coef(fit2)%>% exp()%>% data.frame()
probs<-predict(fit2, type = "response")
table(predict=as.numeric(probs>.5), truth=project2$y)%>%addmargins
74/118#TPR Sensitivity
81/118#TNR Specificity
74/111#Precision PPV

project2$logit<-predict(fit2) #get predicted log-odds
ggplot(project2,aes(logit, fill=`Rural/Urban`))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2)
library(plotROC)
ROCplot<-ggplot(project2)+geom_roc(aes(d=y, m=probs), n.cuts=0)
ROCplot
calc_auc(ROCplot)
set.seed(1234) 
k=10
data<-project2[sample(nrow(project2)),]
folds<-cut(seq(1:nrow(project2)),breaks=k, labels=F)
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$y
  fit<-glm(y~Lifeexpt+pctinsufficientsleep, data=train, family="binomial")
  probs<-predict(fit, newdata=test, type="response")
  diags<-rbind(diags, class_diag(probs,truth))
}
summarize_all(diags, mean)
```
This logistic regression is prediciting if a county is Mostly Urban or Mostly Rural based on life expectancy and percent of the population getting insufficient sleep. In the model Mostly Rural and Mostly Urban are a binary classification with 1 representing Mostly Urban and 0 representing Mostly Rural. These coefficient show that going up 1 year in life expectancy increases the log-odds by .204 and going up by 1% of insufficent sleep increases the log-odds score of being a Mostly Urban county by .462.The coefficient when exponentiated show that an increase of 1  year of life expectancy increases the odds of being a Mostly Urban county by 1.27 and a 1% increase of insufficent sleep raises the odds of being a Mostly Urban county by 1.587.  
The TPR is .627
The TNR is .686
The PPV is .667
The ROC plot visualizes the tradeoff between sensitivity and specificity. Based on the graph the model is predicting fairly, but it could be improved. The AUC has a value of .726 which means that life expectancy and percent insufficient sleep are fair predictors of whether a county is mostly urban or mostly rural.
The 10-fold cross validation had an accuracy of .65, a sensitivity of .609, a specificity of .685, a ppv of .667, and an auc of .719. These values were slightly lower than the in-sample model. The results from the 10-fold cross validation do not differ greatly from the original model showing that the original model was not overfitting the data significantly. 


# Linear LASSO Regression 
```{R}
library(glmnet)

fulldata%>%select(County,`Life Expectancy`,`% Adults with Obesity`,`% Physically Inactive`,`% Smokers`,`% Food Insecure`,`% Uninsured`,`% Adults with Diabetes`,`Percent of adults with a bachelor's degree or higher, 2014-18`, `Median Household Income`, `% Insufficient Sleep`,`% Excessive Drinking`,`% Rural`)->project2.1
project2.1%>% na.omit()->project2.1
project2.1%>% rename(Lifeexpt=`Life Expectancy`)%>% rename(pctObese=`% Adults with Obesity`)%>% rename(pctInactive=`% Physically Inactive`)%>% rename(pctFDInsecure=`% Food Insecure`)%>% rename(pctSmokers=`% Smokers`)%>% rename(pctUninsured=`% Uninsured`)%>% rename(pctDiabetes=`% Adults with Diabetes`)%>% rename(pctBachelors=`Percent of adults with a bachelor's degree or higher, 2014-18`)%>% rename(medianincome=`Median Household Income`)%>% rename(pctinsufficientsleep=`% Insufficient Sleep`)%>% rename(pctRural=`% Rural`)%>% rename(pctexcessdrinking=`% Excessive Drinking`)->project2.1
project2.1%>% select(2:12)->project2.1


y<-as.matrix(project2.1$Lifeexpt)
x<-project2.1%>% select(-Lifeexpt)%>% mutate_all(scale)%>% as.matrix()
cv<-cv.glmnet(x,y) 
lasso<-glmnet(x,y, lambda = cv$lambda.1se)
coef(lasso)
fit1.0<-lm(Lifeexpt~pctFDInsecure+pctBachelors, data = project2.1)
summary(fit1.0)
summary(fit1)
```
# Binary Lasso Regression
```{R}
a<-as.matrix(project2$y)
b<-model.matrix(y~pctObese+pctInactive+pctSmokers+pctFDInsecure+pctUninsured+pctDiabetes+pctBachelors+medianincome+pctinsufficientsleep+pctexcessdrinking, data=project2)[,-1]
cv<-cv.glmnet(b,a,family="binomial") 
lasso<-glmnet(b,a,family="binomial",lambda=cv$lambda.1se) 
coef(lasso)
set.seed(1234) 
k=10
data<-project2[sample(nrow(project2)),]
folds<-cut(seq(1:nrow(project2)),breaks=k, labels=F)
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$y
  fit<-glm(y~pctFDInsecure+pctBachelors+pctinsufficientsleep+pctexcessdrinking, data=train, family="binomial")
  probs<-predict(fit, newdata=test, type="response")
  diags<-rbind(diags, class_diag(probs,truth))
}
summarize_all(diags, mean)
```
I chose to compare predict both a binary variable and a continuous variable.The binary variable chosen to predict was if a county was Mostly Urban or Mostly Rural, while the continous varible to predict was life expectancy.

In the Linear Lasso Regression the variables that were retained were percent Obesity, percent Inactive, percent Food insecure, percent uninsured, percent Bachelor's degree, median income, percent insufficient sleep, and percent excess drinking. A linear regression with these models provided a residual standard error of 1.9 which is lower compared to the previous linear model predicting life expectancy which had a residual standard error of 2.0 

The variables that were retained in the Binary lasso regression were percent Food Insecure, percent Bachelors degree, percent insufficient sleep, and percent excess drinking. These variables were then used in 10-fold cross validation. The model had an accuracy of .731, and sensitivity of .723, a specificity of .743, a ppv of .740, and an significantly higher AUC of .81 when compared to the previous logisitc regression AUC of .717. This new model computed from variables from the LASSO regession is classified as a good AUC. This model is predicting whether a county is urban or rural much better. 







...





